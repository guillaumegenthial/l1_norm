{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build the data\n",
    "\n",
    "See `build_data.py`\n",
    "\n",
    "We need to generate some data. Requirements:\n",
    "- enough to train, not too much for speed issues\n",
    "- train and dev sets ideally have the same distribution\n",
    "- test set distribution ideally a bit different\n",
    "- should be reproducible (fix random seed)\n",
    "- randomize dimension of vectors and scale of the distribution\n",
    "- saves data to files for future re-use of the model\n",
    "\n",
    "Then, the file `model/input_fn.py` takes care of the input data pipeline to the Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from build_data import get_one_example\n",
    "from build_data import export_to_file\n",
    "from build_data import save_dict_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "random.seed(2018)\n",
    "\n",
    "# Define hyper parameters of the dataset\n",
    "DATA_PARENT_DIR = \"data\"\n",
    "# Sizes\n",
    "TRAIN_SIZE = 8000\n",
    "TEST_SIZE = 1000\n",
    "DEV_SIZE = 1000\n",
    "# Dimensions - test distribution is wider\n",
    "TRAIN_DIMENSION_LOW = 10\n",
    "TRAIN_DIMENSION_UPP = 200\n",
    "TEST_DIMENSION_LOW = 1\n",
    "TEST_DIMENSION_UPP = 400\n",
    "# Scales - test distribution is wider\n",
    "TRAIN_SCALE_LOW = 1\n",
    "TRAIN_SCALE_UPP = 10\n",
    "TEST_SCALE_LOW = 0.1\n",
    "TEST_SCALE_UPP = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the datasets\n",
    "data_train = [get_one_example(TRAIN_DIMENSION_LOW, TRAIN_DIMENSION_UPP,\n",
    "                              TRAIN_SCALE_LOW, TRAIN_SCALE_UPP)\n",
    "              for _ in range(TRAIN_SIZE)]\n",
    "data_dev = [get_one_example(TRAIN_DIMENSION_LOW, TRAIN_DIMENSION_UPP,\n",
    "                              TRAIN_SCALE_LOW, TRAIN_SCALE_UPP)\n",
    "              for _ in range(DEV_SIZE)]\n",
    "data_test = [get_one_example(TEST_DIMENSION_LOW, TEST_DIMENSION_UPP,\n",
    "                              TEST_SCALE_LOW, TEST_SCALE_UPP)\n",
    "              for _ in range(TEST_SIZE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to files\n",
    "if not os.path.exists(DATA_PARENT_DIR):\n",
    "    os.makedirs(DATA_PARENT_DIR)\n",
    "\n",
    "export_to_file(data_train, \"train.x\", \"train.y\")\n",
    "export_to_file(data_dev, \"dev.x\", \"dev.y\")\n",
    "export_to_file(data_test, \"test.x\", \"test.y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets properties in json file\n",
    "sizes = {\n",
    "    'train_size': len(data_train),\n",
    "    'dev_size': len(data_dev),\n",
    "    'test_size': len(data_test),\n",
    "}\n",
    "\n",
    "save_dict_to_json(sizes, os.path.join(DATA_PARENT_DIR, 'dataset_params.json'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define the model\n",
    "\n",
    "See `model/model_fn.py`\n",
    "\n",
    "Obviously, the L1 norm of x_1, ...., x_n can be computed with the following graph\n",
    "\n",
    "```\n",
    "# shape = [batch_size, max_dimension in batch] (padded with zeros)\n",
    "out = input_vectors\n",
    "\n",
    "# Compute the absolute norm of every entry\n",
    "out = tf.nn.relu(out) + tf.nn.relu(-out)\n",
    "\n",
    "# Sum over the last dimension\n",
    "out = tf.reduce_sum(out, axis=-1)\n",
    "```\n",
    "\n",
    "It respects the requirement (only ReLUs, +, - and sum), but there is no learnable component...\n",
    "We can also test if we can learn the right connection for the 2 dense layers (learn this: [1, -1] -> relu -> [1, 1] -> reduce_sum or [a, -b] -> relu -> [1/a, 1/b] -> reduce_sum with a, b > 0).\n",
    "\n",
    "The operations of such a graph are summed up below: we need to take care of padding because of different dimensions in a batch\n",
    "\n",
    "\n",
    "```\n",
    "# shape = [batch_size, max_dimension in batch, 1]\n",
    "out = tf.expand_dims(out, axis=-1)\n",
    "\n",
    "out = tf.layers.dense(out, 2, activation=tf.nn.relu, use_bias=False)\n",
    "out = tf.layers.dense(out, 1, activation=None, use_bias=False)\n",
    "\n",
    "# length is a tensor of shape [batch_size] of int where length[i] is the dim of the i-th example\n",
    "# shape = [batch_size, max dimension in batch, 1]\n",
    "mask = tf.expand_dims(tf.cast(tf.sequence_mask(lengths), tf.float32), axis=-1)\n",
    "# shape = [batch_size]\n",
    "predictions = tf.reduce_sum(tf.reduce_sum(outputs * mask, axis=-1), axis=-1)\n",
    "\n",
    "# Loss\n",
    "sum_of_dims = tf.reduce_sum(lengths)\n",
    "l2_loss = tf.reduce_mean(tf.square(predictions - labels))\n",
    "loss = l2_loss / tf.cast(sum_of_dims, tf.float32) # loss per component for indep to other hp\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.utils import Params\n",
    "from model.utils import set_logger\n",
    "from model.training import train_and_evaluate\n",
    "from model.input_fn import input_fn\n",
    "from model.input_fn import load_dataset_from_text\n",
    "from model.model_fn import model_fn\n",
    "\n",
    "# Set the random seed for the whole graph for reproductible experiments\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(230)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import hyperparams and setup the logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'batch_size': 32, 'num_epochs': 15, 'model_version': 'trainable', 'save_summary_steps': 100, 'train_size': 8000, 'dev_size': 1000, 'test_size': 1000}\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"experiments/base_model\"\n",
    "data_dir = \"data\"\n",
    "\n",
    "# Load the parameters from the experiment params.json file in model_dir\n",
    "json_path = os.path.join(model_dir, 'params.json')\n",
    "assert os.path.isfile(json_path), \"No json configuration file found at {}\".format(json_path)\n",
    "params = Params(json_path)\n",
    "\n",
    " # Load the parameters from the dataset, that gives the size etc. into params\n",
    "json_path = os.path.join(data_dir, 'dataset_params.json')\n",
    "params.update(json_path)\n",
    "\n",
    "# Set the logger\n",
    "set_logger(os.path.join(model_dir, 'train.log'))\n",
    "print(params.dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, load the vectors and l1 norm with tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating the datasets...\n"
     ]
    }
   ],
   "source": [
    "# Get paths for vocabularies and dataset\n",
    "path_train_x = os.path.join(data_dir, 'train.x')\n",
    "path_train_y = os.path.join(data_dir, 'train.y')\n",
    "path_eval_x = os.path.join(data_dir, 'dev.x')\n",
    "path_eval_y = os.path.join(data_dir, 'dev.y')\n",
    "\n",
    "# Create the input data pipeline\n",
    "logging.info(\"Creating the datasets...\")\n",
    "train_x = load_dataset_from_text(path_train_x)\n",
    "train_labels = load_dataset_from_text(path_train_y)\n",
    "eval_x = load_dataset_from_text(path_eval_x)\n",
    "eval_labels = load_dataset_from_text(path_eval_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create the input function and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- done.\n",
      "Creating the model...\n",
      "- done.\n"
     ]
    }
   ],
   "source": [
    "# Specify other parameters for the dataset and the model\n",
    "params.eval_size = params.dev_size\n",
    "params.buffer_size = params.train_size # buffer size for shuffling\n",
    "\n",
    "# Create the two iterators over the two datasets\n",
    "train_inputs = input_fn('train', train_x, train_labels, params)\n",
    "eval_inputs = input_fn('eval', eval_x, eval_labels, params)\n",
    "logging.info(\"- done.\")\n",
    "\n",
    "# Define the models (2 different set of nodes that share weights for train and eval)\n",
    "logging.info(\"Creating the model...\")\n",
    "train_model_spec = model_fn('train', train_inputs, params)\n",
    "eval_model_spec = model_fn('eval', eval_inputs, params, reuse=True)\n",
    "logging.info(\"- done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train the model\n",
    "\n",
    "\n",
    "### Training and Hyperparameters\n",
    "\n",
    "- Applying Dropout would not make sense as the architecture is as minimalist as possible. L2 regularization would introduce a bias, even though it would penalize high values of the weights (that work, [a, -b] and [1/a, 1/b] are valid weights for all a for our 2 layer network)\n",
    "- Relevant hyperparameters are batch_size, learning_rate, optimization method.\n",
    "- Training loss is the L2 loss between the average per component of the predicted L1 norm and the gold L1 norm\n",
    "- We take the average per component and per batch so that changing other hyperparameters does not impact the choice of learning_rate and batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting training for 15 epoch(s)\n",
      "Epoch 1/15\n",
      "100%|██████████| 250/250 [00:06<00:00, 41.59it/s, loss=37.741] \n",
      "- Train metrics: loss: 37.387 ; neg_l2_loss: -4572.417 ; accuracy: -37.387\n",
      "- Eval metrics: loss: 10.483 ; neg_l2_loss: -1476.145 ; accuracy: -10.483\n",
      "- Found new best accuracy, saving in experiments/base_model/best_weights/after-epoch-1\n",
      "Epoch 2/15\n",
      "100%|██████████| 250/250 [00:05<00:00, 42.75it/s, loss=17.308] \n",
      "- Train metrics: loss: 39.121 ; neg_l2_loss: -4852.249 ; accuracy: -39.121\n",
      "- Eval metrics: loss: 9.884 ; neg_l2_loss: -1424.880 ; accuracy: -9.884\n",
      "- Found new best accuracy, saving in experiments/base_model/best_weights/after-epoch-2\n",
      "Epoch 3/15\n",
      "100%|██████████| 250/250 [00:06<00:00, 40.30it/s, loss=10.150] \n",
      "- Train metrics: loss: 36.197 ; neg_l2_loss: -4571.680 ; accuracy: -36.197\n",
      "- Eval metrics: loss: 9.861 ; neg_l2_loss: -1460.083 ; accuracy: -9.861\n",
      "- Found new best accuracy, saving in experiments/base_model/best_weights/after-epoch-3\n",
      "Epoch 4/15\n",
      "100%|██████████| 250/250 [00:06<00:00, 39.76it/s, loss=9.022]  \n",
      "- Train metrics: loss: 35.194 ; neg_l2_loss: -4458.922 ; accuracy: -35.194\n",
      "- Eval metrics: loss: 9.912 ; neg_l2_loss: -1476.168 ; accuracy: -9.912\n",
      "Epoch 5/15\n",
      "100%|██████████| 250/250 [00:06<00:00, 39.73it/s, loss=8.601]  \n",
      "- Train metrics: loss: 34.834 ; neg_l2_loss: -4415.645 ; accuracy: -34.834\n",
      "- Eval metrics: loss: 9.938 ; neg_l2_loss: -1483.421 ; accuracy: -9.938\n",
      "Epoch 6/15\n",
      "100%|██████████| 250/250 [00:07<00:00, 35.66it/s, loss=8.409]  \n",
      "- Train metrics: loss: 34.651 ; neg_l2_loss: -4393.176 ; accuracy: -34.651\n",
      "- Eval metrics: loss: 9.951 ; neg_l2_loss: -1486.984 ; accuracy: -9.951\n",
      "Epoch 7/15\n",
      "100%|██████████| 250/250 [00:06<00:00, 38.67it/s, loss=8.312]  \n",
      "- Train metrics: loss: 34.548 ; neg_l2_loss: -4380.443 ; accuracy: -34.548\n",
      "- Eval metrics: loss: 9.957 ; neg_l2_loss: -1488.841 ; accuracy: -9.957\n",
      "Epoch 8/15\n",
      "100%|██████████| 250/250 [00:06<00:00, 37.05it/s, loss=8.270]  \n",
      "- Train metrics: loss: 34.487 ; neg_l2_loss: -4372.794 ; accuracy: -34.487\n",
      "- Eval metrics: loss: 9.957 ; neg_l2_loss: -1489.135 ; accuracy: -9.957\n",
      "Epoch 9/15\n",
      "100%|██████████| 250/250 [00:06<00:00, 38.22it/s, loss=6.660]  \n",
      "- Train metrics: loss: 34.949 ; neg_l2_loss: -4450.463 ; accuracy: -34.949\n",
      "- Eval metrics: loss: 4.424 ; neg_l2_loss: -656.735 ; accuracy: -4.424\n",
      "- Found new best accuracy, saving in experiments/base_model/best_weights/after-epoch-9\n",
      "Epoch 10/15\n",
      "100%|██████████| 250/250 [00:06<00:00, 39.35it/s, loss=37.110] \n",
      "- Train metrics: loss: 12.266 ; neg_l2_loss: -1503.196 ; accuracy: -12.266\n",
      "- Eval metrics: loss: 9.050 ; neg_l2_loss: -1512.835 ; accuracy: -9.050\n",
      "Epoch 11/15\n",
      "100%|██████████| 250/250 [00:06<00:00, 39.42it/s, loss=0.338] \n",
      "- Train metrics: loss: 4.752 ; neg_l2_loss: -579.740 ; accuracy: -4.752\n",
      "- Eval metrics: loss: 0.029 ; neg_l2_loss: -4.886 ; accuracy: -0.029\n",
      "- Found new best accuracy, saving in experiments/base_model/best_weights/after-epoch-11\n",
      "Epoch 12/15\n",
      "100%|██████████| 250/250 [00:07<00:00, 31.65it/s, loss=0.000]\n",
      "- Train metrics: loss: 0.059 ; neg_l2_loss: -6.790 ; accuracy: -0.059\n",
      "- Eval metrics: loss: 0.000 ; neg_l2_loss: -0.004 ; accuracy: -0.000\n",
      "- Found new best accuracy, saving in experiments/base_model/best_weights/after-epoch-12\n",
      "Epoch 13/15\n",
      "100%|██████████| 250/250 [00:07<00:00, 35.01it/s, loss=0.000]\n",
      "- Train metrics: loss: 0.000 ; neg_l2_loss: -0.001 ; accuracy: -0.000\n",
      "- Eval metrics: loss: 0.000 ; neg_l2_loss: -0.000 ; accuracy: -0.000\n",
      "- Found new best accuracy, saving in experiments/base_model/best_weights/after-epoch-13\n",
      "Epoch 14/15\n",
      "100%|██████████| 250/250 [00:07<00:00, 35.01it/s, loss=0.000]\n",
      "- Train metrics: loss: 0.000 ; neg_l2_loss: -0.000 ; accuracy: -0.000\n",
      "- Eval metrics: loss: 0.000 ; neg_l2_loss: -0.000 ; accuracy: -0.000\n",
      "- Found new best accuracy, saving in experiments/base_model/best_weights/after-epoch-14\n",
      "Epoch 15/15\n",
      "100%|██████████| 250/250 [00:08<00:00, 31.09it/s, loss=0.000]\n",
      "- Train metrics: loss: 0.000 ; neg_l2_loss: -0.000 ; accuracy: -0.000\n",
      "- Eval metrics: loss: 0.000 ; neg_l2_loss: -0.000 ; accuracy: -0.000\n",
      "- Found new best accuracy, saving in experiments/base_model/best_weights/after-epoch-15\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "logging.info(\"Starting training for {} epoch(s)\".format(params.num_epochs))\n",
    "train_and_evaluate(train_model_spec, eval_model_spec, model_dir, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we get a zero error, meaning the weights should be those expected. The learning rate was tuned thanks to `search_hyperparams.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluate on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating the dataset...\n"
     ]
    }
   ],
   "source": [
    "# Reset the default graph\n",
    "from model.evaluation import evaluate\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Get paths for vocabularies and dataset\n",
    "path_eval_x = os.path.join(data_dir, 'dev.x')\n",
    "path_eval_y = os.path.join(data_dir, 'dev.y')\n",
    "\n",
    "# Create the input data pipeline\n",
    "logging.info(\"Creating the dataset...\")\n",
    "test_x = load_dataset_from_text(path_eval_x)\n",
    "test_labels = load_dataset_from_text(path_eval_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- done.\n",
      "Creating the model...\n",
      "- done.\n"
     ]
    }
   ],
   "source": [
    "# Specify other parameters for the dataset and the model\n",
    "params.eval_size = params.test_size\n",
    "\n",
    "# Create iterator over the test set\n",
    "inputs = input_fn('eval', test_x, test_labels, params)\n",
    "logging.info(\"- done.\")\n",
    "\n",
    "# Define the model\n",
    "logging.info(\"Creating the model...\")\n",
    "model_spec = model_fn('eval', inputs, params, reuse=False)\n",
    "logging.info(\"- done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting evaluation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from experiments/base_model/best_weights/after-epoch-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring parameters from experiments/base_model/best_weights/after-epoch-15\n",
      "- Eval metrics: loss: 0.000 ; neg_l2_loss: -0.000 ; accuracy: -0.000\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Starting evaluation\")\n",
    "evaluate(model_spec, model_dir, params, \"best_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Observations\n",
    "\n",
    "- Both models achieve 0 L2 loss between the two L1 norms (neural and gold).\n",
    "- Some sensibility to the learning_rate, resolved with hyperparameter search and the use of Adam.\n",
    "- Ability to generalize as the distribution of the test set is slightly different\n",
    "\n",
    "We can look at the actual predicted values and check that we get what we expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from experiments/base_model/best_weights/after-epoch-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring parameters from experiments/base_model/best_weights/after-epoch-15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.93104327, -1.0230914 ]], dtype=float32), array([[1.0740643],\n",
      "       [0.9774295]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "     # Reload weights from the weights subdirectory\n",
    "    save_path = os.path.join(model_dir, \"best_weights\")\n",
    "    if os.path.isdir(save_path):\n",
    "        save_path = tf.train.latest_checkpoint(save_path)\n",
    "    saver.restore(sess, save_path)\n",
    "\n",
    "    print(sess.run(variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the values found verify\n",
    "\n",
    "0.93 * 1.07 == 1\n",
    "\n",
    "-1.023 * 0.9777 == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
